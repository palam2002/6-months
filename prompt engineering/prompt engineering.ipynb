{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d29f10b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promat created: write a story about a candy game\n"
     ]
    }
   ],
   "source": [
    "promat='write a story about a candy game'\n",
    "\n",
    "print('promat created:',promat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "115d6920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Prompt:  Write a  story about write about  kgf.\n"
     ]
    }
   ],
   "source": [
    "def create_prompt():\n",
    "    topic = input(\"Enter the topic for the story: \")\n",
    "    tone = input (\"Enter the tone (e.g., serious, humorous, adventurous) : \")\n",
    "    prompt = f\"Write a {tone} story about {topic}.\"\n",
    "    return prompt\n",
    "\n",
    "user_prompt = create_prompt()\n",
    "print (\"Generated Prompt: \",user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3906598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write a serious story about AI.\n",
      "write a humorous story about AI.\n",
      "write a adventurous story about AI.\n",
      "write a serious story about space exploration.\n",
      "write a humorous story about space exploration.\n",
      "write a adventurous story about space exploration.\n",
      "write a serious story about ancient history.\n",
      "write a humorous story about ancient history.\n",
      "write a adventurous story about ancient history.\n"
     ]
    }
   ],
   "source": [
    "topics=['AI','space exploration','ancient history',]\n",
    "tones=[' serious',' humorous',' adventurous']\n",
    "prompts=[]\n",
    "for topic in topics:\n",
    "    for tone in tones:\n",
    "        prompt=f'write a{tone} story about {topic}.'\n",
    "        prompts.append(prompt)\n",
    "        \n",
    "        \n",
    "        \n",
    "for promat in prompts:\n",
    "    print(promat)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9227aa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary promat: AI is rapidly chaging the way we work,communicate,and live. Write a concise summary of the key points discussed in the following text:\n",
      "\n",
      "Ai is transforming various industries by automating tasks, enhancing decision-making, and enabling new capabilities. It is also raising ethical and societal questions that need to be addressed.\n",
      "\n",
      "Summary:\n"
     ]
    }
   ],
   "source": [
    "def create_summary_prompt(text):\n",
    "    prompt_template='AI is rapidly chaging the way we work,communicate,and live. Write a concise summary of the key points discussed in the following text:\\n\\n'+text+'\\n\\nSummary:'\n",
    "    return prompt_template.format(text=text)\n",
    "\n",
    "input_text=\"Ai is transforming various industries by automating tasks, enhancing decision-making, and enabling new capabilities. It is also raising ethical and societal questions that need to be addressed.\"\n",
    "summary_prompt=create_summary_prompt(input_text)\n",
    "print(\"Generated summary promat:\",summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a28b6b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain quantum computing in simple terms.\n",
      "Explain blockchain technology in simple terms.\n",
      "Explain gene editing in simple terms.\n"
     ]
    }
   ],
   "source": [
    "def generate_prompts_from_data(data_list):\n",
    "    prompts = []\n",
    "    for item in data_list:\n",
    "        prompt = f'Explain {item} in simple terms.'\n",
    "        prompts.append(prompt)\n",
    "    return prompts\n",
    "\n",
    "data_list = ['quantum computing', 'blockchain technology', 'gene editing']\n",
    "prompts = generate_prompts_from_data(data_list)\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b265ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated f-string literal (detected at line 5) (1689686818.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    step2_prompt = f\"Based on the summary: '{ai_summary}', answer the following question:\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated f-string literal (detected at line 5)\n"
     ]
    }
   ],
   "source": [
    "def create_stepwise_promat(context):\n",
    "    step1_promat=f\"Summarize this text:{context}\"\n",
    "    \n",
    "    ai_summary = \"This is a summary of the context.\" # Placeholder for the actual AI API\n",
    "    step2_prompt = f\"Based on the summary: '{ai_summary}', answer the following question:\n",
    "    return step1_prompt, step2_prompt\n",
    "context = \"Artificial intelligence has become a pivotal technology in the 21st century...\"\n",
    "stepl, step2 = create_stepwise_prompt(context)\n",
    "print(\"Step 1 Prompt:\", step1)\n",
    "print(\"Step 2 Prompt:\",step2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever_info(query):\n",
    "    return 'about elon musk'\n",
    "\n",
    "\n",
    "def rag_query(query):\n",
    "    retrieved_info=retriever_info(query)\n",
    "    augmented_promat=f'User quert: {query}. Retrieved info: {retrieved_info}.'\n",
    "    \n",
    "    \n",
    "response=openai.ChatCompletion.create(\n",
    "    model='gpt-4',\n",
    "    messages=[\n",
    "        {'role':'user', 'content':augmented_promat}\n",
    "    ],\n",
    "    max_tokens=100,\n",
    "    temperature=0.2,\n",
    "    top p=1,\n",
    "    frequency_penalty=0,\n",
    "    \n",
    ")\n",
    "\n",
    "    return response.choices[0].message['content'].strip()\n",
    "\n",
    "\n",
    "query='Tell me about the elon musk' \n",
    "response=rag_query(query)\n",
    "print('Response:',response)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbfcaa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-07 17:13:40.567 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-10-07 17:13:40.567 Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIGURATION\n",
    "# -------------------------------\n",
    "st.set_page_config(page_title=\"Gemini RAG App\", page_icon=\"ü§ñ\", layout=\"centered\")\n",
    "st.title(\"ü§ñ Gemini RAG Demo App\")\n",
    "\n",
    "# Gemini API Key input (for demo purposes)\n",
    "api_key = st.text_input(\"üîë Enter your Gemini API Key\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "    # Dummy retriever for demonstration\n",
    "    def retriever_info(query):\n",
    "        # Here you could add a vector search, database lookup, or PDF retriever\n",
    "        return \"about Elon Musk\"\n",
    "\n",
    "    # Main RAG function\n",
    "    def rag_query(query):\n",
    "        retrieved_info = retriever_info(query)\n",
    "        augmented_prompt = f\"User query: {query}. Retrieved information: {retrieved_info}\"\n",
    "\n",
    "        model_name = \"gemini-1.5-flash\"  # try \"gemini-pro\" if flash not available\n",
    "        model = genai.GenerativeModel(model_name)\n",
    "\n",
    "        response = model.generate_content(\n",
    "            augmented_prompt,\n",
    "            generation_config={\n",
    "                \"temperature\": 0.2,\n",
    "                \"max_output_tokens\": 300\n",
    "            }\n",
    "        )\n",
    "        return response.text.strip()\n",
    "\n",
    "    # -------------------------------\n",
    "    # UI Section\n",
    "    # -------------------------------\n",
    "    query = st.text_area(\"üí¨ Ask a question:\", \"Tell me about Elon Musk\")\n",
    "\n",
    "    if st.button(\"üîç Generate Response\"):\n",
    "        if not query.strip():\n",
    "            st.warning(\"Please enter a query first.\")\n",
    "        else:\n",
    "            with st.spinner(\"Generating response...\"):\n",
    "                try:\n",
    "                    answer = rag_query(query)\n",
    "                    st.success(\"‚úÖ Response Generated!\")\n",
    "                    st.markdown(f\"**Answer:**\\n\\n{answer}\")\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Error: {e}\")\n",
    "else:\n",
    "    st.info(\"Please enter your Gemini API key to start.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Footer\n",
    "# -------------------------------\n",
    "st.markdown(\"---\")\n",
    "st.caption(\"Built with ‚ù§Ô∏è using Streamlit + Google Gemini API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c1a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
